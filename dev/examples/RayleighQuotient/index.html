<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>The Rayleigh Quotient ¬∑ ManoptExamples.jl</title><meta name="title" content="The Rayleigh Quotient ¬∑ ManoptExamples.jl"/><meta property="og:title" content="The Rayleigh Quotient ¬∑ ManoptExamples.jl"/><meta property="twitter:title" content="The Rayleigh Quotient ¬∑ ManoptExamples.jl"/><meta name="description" content="Documentation for ManoptExamples.jl."/><meta property="og:description" content="Documentation for ManoptExamples.jl."/><meta property="twitter:description" content="Documentation for ManoptExamples.jl."/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/favicon.ico" rel="icon" type="image/x-icon"/><link href="../../assets/citations.css" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../../">ManoptExamples.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><span class="tocitem">Examples</span><ul><li><a class="tocitem" href="../">Overview</a></li><li><input class="collapse-toggle" id="menuitem-2-2" type="checkbox"/><label class="tocitem" for="menuitem-2-2"><span class="docs-label">Difference of Convex</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../Difference-of-Convex-Benchmark/">A Benchmark</a></li><li><a class="tocitem" href="../Difference-of-Convex-Rosenbrock/">Rosenbrock Metric</a></li><li><a class="tocitem" href="../Difference-of-Convex-Frank-Wolfe/">Frank Wolfe comparison</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-2-3" type="checkbox"/><label class="tocitem" for="menuitem-2-3"><span class="docs-label">Convex Bundle Method</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../RCBM-Median/">Riemannian Median</a></li><li><a class="tocitem" href="../H2-Signal-TV/">Hyperbolic Signal Denoising</a></li><li><a class="tocitem" href="../Spectral-Procrustes/">Spectral Procrustes</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-2-4" type="checkbox"/><label class="tocitem" for="menuitem-2-4"><span class="docs-label">Projected Gradient Algorithm</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../Constrained-Mean-H2/">Mean on <span>$\mathbb H^2$</span></a></li><li><a class="tocitem" href="../Constrained-Mean-Hn/">Mean on <span>$\mathbb H^n$</span></a></li></ul></li><li><a class="tocitem" href="../HyperparameterOptimization/">Hyperparameter optimziation</a></li><li class="is-active"><a class="tocitem" href>The Rayleigh Quotient</a><ul class="internal"><li><a class="tocitem" href="#Introduction"><span>Introduction</span></a></li><li><a class="tocitem" href="#Summary"><span>Summary</span></a></li><li><a class="tocitem" href="#Literature"><span>Literature</span></a></li></ul></li><li><a class="tocitem" href="../Riemannian-mean/">Riemannian Mean</a></li><li><input class="collapse-toggle" id="menuitem-2-8" type="checkbox"/><label class="tocitem" for="menuitem-2-8"><span class="docs-label">Proximal Gradient Methods</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../NCRPG-Sparse-PCA/">Sparse PCA</a></li><li><a class="tocitem" href="../NCRPG-Grassmann/">Grassmann Experiment</a></li><li><a class="tocitem" href="../NCRPG-Row-Sparse-Low-Rank/">Row-Sparse Low-Rank Matrix Recovery</a></li><li><a class="tocitem" href="../CRPG-Convex-SPD/">Convex Example on SPDs</a></li><li><a class="tocitem" href="../CRPG-Sparse-Approximation/">Sparse Approximation on <span>$\mathbb H^n$</span></a></li><li><a class="tocitem" href="../CRPG-Constrained-Mean-Hn/">Mean on <span>$\mathbb H^n$</span></a></li></ul></li><li><a class="tocitem" href="../Robust-PCA/">Robust PCA</a></li><li><a class="tocitem" href="../Rosenbrock/">Rosenbrock</a></li><li><a class="tocitem" href="../Total-Variation/">Total Variation</a></li></ul></li><li><a class="tocitem" href="../../objectives/">Objectives</a></li><li><a class="tocitem" href="../../data/">Data</a></li><li><a class="tocitem" href="../../contributing/">Contributing to ManoptExamples.jl</a></li><li><a class="tocitem" href="../../changelog/">Changelog</a></li><li><a class="tocitem" href="../../references/">References</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Examples</a></li><li class="is-active"><a href>The Rayleigh Quotient</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>The Rayleigh Quotient</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/JuliaManifolds/ManoptExamples.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands">ÔÇõ</span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/JuliaManifolds/ManoptExamples.jl/blob/main/docs/src/examples/RayleighQuotient.md" title="Edit source on GitHub"><span class="docs-icon fa-solid">ÔÅÑ</span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="The-Rayleigh-Quotient"><a class="docs-heading-anchor" href="#The-Rayleigh-Quotient">The Rayleigh Quotient</a><a id="The-Rayleigh-Quotient-1"></a><a class="docs-heading-anchor-permalink" href="#The-Rayleigh-Quotient" title="Permalink"></a></h1><p>Ronny Bergmann 2024-03-09</p><h2 id="Introduction"><a class="docs-heading-anchor" href="#Introduction">Introduction</a><a id="Introduction-1"></a><a class="docs-heading-anchor-permalink" href="#Introduction" title="Permalink"></a></h2><p>This example reproduces a few conceptual ideas of Optimization on Manifolds that are used throughout [<a href="../../references/#Boumal_2023">Bou23</a>] using the Rayleigh quotient and explores several different ways to use the algorithms from <a href="https://manoptjl.org"><code>Manopt.jl</code></a>.</p><p>For a symmetric matrix <span>$A \in \mathbb R^{n\times n}$</span> we consider the <a href="https://en.wikipedia.org/wiki/Rayleigh_quotient">üìñ Rayleigh Quotient</a></p><p class="math-container">\[\operatorname*{arg\,min}_{x \in \mathbb R^n \backslash \{0\}}
\frac{x^{\mathrm{T}}Ax}{\lVert x¬†\rVert^2}.\]</p><p>On the sphere we can omit the denominator and obtain</p><p class="math-container">\[f(p) = p^{\mathrm{T}}Ap,\qquad p ‚àà ùïä^{n-1},\]</p><p>which by itself we can again continue in the embedding as</p><p class="math-container">\[\tilde f(x) = x^{\mathrm{T}}Ax,\qquad x \in \mathbb R^n.\]</p><p>This cost has the nice feature that at the minimizer <span>$p^*\in\mathbb S^{n-1}$</span> the function falue <span>$f(p^*)$</span> is the smalles eigenvalue of <span>$A$</span>.</p><p>For the embedded function <span>$\tilde f$</span> the gradient and Hessian can be computed with classical methods as</p><p class="math-container">\[\begin{align*}
‚àá\tilde f(x) &amp;= 2Ax, \qquad x ‚àà ‚Ñù^n,
\\
‚àá^2\tilde f(x)[V] &amp;= 2AV, \qquad x, V ‚àà ‚Ñù^n.
\end{align*}\]</p><p>Similarly, cf.¬†Examples 3.62 and 5.27 of [<a href="../../references/#Boumal_2023">Bou23</a>], the Riemannian gradient and Hessian on the manifold <span>$\mathcal M = \mathbb S^{n-1}$</span> are given by</p><p class="math-container">\[\begin{align*}
\operatorname{grad} f(p) &amp;= 2Ap - 2(p^{\mathrm{T}}Ap)*p,\qquad p ‚àà ùïä^{n-1},
\\
\operatorname{Hess} f(p)[X] &amp;=  2AX - 2(p^{\mathrm{T}}AX)p - 2(p^{\mathrm{T}}Ap)X,\qquad p ‚àà ùïä^{n-1}, X \in T_pùïä^{n-1}
\end{align*}\]</p><p>Let‚Äôs first generate an example martrx <span>$A$</span>.</p><pre><code class="language-julia hljs">using Pkg;
cd(@__DIR__)
Pkg.activate(&quot;.&quot;); # use the example environment,</code></pre><pre><code class="language-julia hljs">using LRUCache, BenchmarkTools, LinearAlgebra, Manifolds, ManoptExamples, Manopt, Random
Random.seed!(42)
n = 500
A = Symmetric(randn(n, n) / n)</code></pre><p>And the manifolds</p><pre><code class="language-julia hljs">M = Sphere(n-1)</code></pre><pre><code class="nohighlight hljs">Sphere(499, ‚Ñù)</code></pre><pre><code class="language-julia hljs">E = get_embedding(M)</code></pre><pre><code class="nohighlight hljs">Euclidean(500; field=‚Ñù)</code></pre><h3 id="Setup-the-corresponding-functions"><a class="docs-heading-anchor" href="#Setup-the-corresponding-functions">Setup the corresponding functions</a><a id="Setup-the-corresponding-functions-1"></a><a class="docs-heading-anchor-permalink" href="#Setup-the-corresponding-functions" title="Permalink"></a></h3><p>Since <a href="../../objectives/#ManoptExamples.RayleighQuotientCost"><code>RayleighQuotientCost</code></a>, <a href="../../objectives/#ManoptExamples.RayleighQuotientGrad!!"><code>RayleighQuotientGrad!!</code></a>, and <a href="../../objectives/#ManoptExamples.RayleighQuotientHess!!"><code>RayleighQuotientHess!!</code></a> are themselves manifold agnostic we only need to initialize them once. Agnostic here means that they would compute <span>$f$</span> is called with <code>M</code> as their first argument and <span>$\tilde f$</span> if called with <code>E</code>.</p><p>We instantiate</p><pre><code class="language-julia hljs">f = ManoptExamples.RayleighQuotientCost(A)
grad_f = ManoptExamples.RayleighQuotientGrad!!(A)
Hess_f = ManoptExamples.RayleighQuotientHess!!(A)</code></pre><p>the suffix <code>!!</code> also indicates that these functions both work as allocating and in-place variants. Given a starting point and some memory</p><pre><code class="language-julia hljs">p0 = [1.0, zeros(n-1)...]
X = zero_vector(M, p0)</code></pre><p>we can both call</p><pre><code class="language-julia hljs">Y = grad_f(M, p0)  # Allocates memory
grad_f(M, X, p0)    # Computes in place of X and returns the result in X.
norm(M, p0, X-Y)</code></pre><pre><code class="nohighlight hljs">0.0</code></pre><p>Now we can use a few different variants of solvers to approaach this and this tutorial will walk you through a few of them.</p><p>First of all let‚Äôs construct the actual result ‚Äì¬†since Rayleigh quotient minimization is not necessarily the best way to compute the smallest Eigenvalue. We can also compute</p><pre><code class="language-julia hljs">Œª = min(eigvals(A)...)</code></pre><pre><code class="nohighlight hljs">-0.08924035897103727</code></pre><h3 id="A-Solver-based-on-gradient-information"><a class="docs-heading-anchor" href="#A-Solver-based-on-gradient-information">A Solver based on gradient information</a><a id="A-Solver-based-on-gradient-information-1"></a><a class="docs-heading-anchor-permalink" href="#A-Solver-based-on-gradient-information" title="Permalink"></a></h3><p>Let‚Äôs first just use first-order information and since we are just starting, maybe we only derived the Euclidean gradient <span>$\nabla \tilde f$</span>. We can ‚Äútell‚Äù the solver, that the provided function and the gradient are defined as the Euclidean variants in the embedding. internally, <code>Manopt.jl</code> then issues the conversion for Euclidean gradients to the corresponding Riemannian one, cf.¬†e.g.¬†<a href="https://manoptjl.org/stable/tutorials/AutomaticDifferentiation/#EmbeddedGradient">this tutorial section</a> or Section 3.8 or more precisely Example 3.62 in [<a href="../../references/#Boumal_2023">Bou23</a>].</p><p>But instead of diving into all the tecnical details, we can just specify <code>objective_type=:Euclidean</code> to trigger the conversion. We start with a simple <a href="https://manoptjl.org/stable/solvers/gradient_descent/">gradient descent</a></p><pre><code class="language-julia hljs">s = gradient_descent(M, f, grad_f, p0; objective_type=:Euclidean,
    debug = [:Iteration, :Cost, :GradientNorm, 50, &quot;\n&quot;],
    return_state=true,
)
q1 = get_solver_result(s)
s</code></pre><pre><code class="nohighlight hljs">Initial f(x): -0.000727
# 50    f(x): -0.088242|grad f(p)|:0.003870474326981599
# 100   f(x): -0.088680|grad f(p)|:0.0034956568288634616
# 150   f(x): -0.089026|grad f(p)|:0.0026514781676923237
# 200   f(x): -0.089178|grad f(p)|:0.001531160335922979

# Solver state for `Manopt.jl`s Gradient Descent
After 200 iterations

## Parameters
* retraction method: ExponentialRetraction()

## Stepsize
ArmijoLinesearch(;
    initial_stepsize=1.0
    retraction_method=ExponentialRetraction()
    contraction_factor=0.95
    sufficient_decrease=0.1
)

## Stopping criterion

Stop When _one_ of the following are fulfilled:
  * Max Iteration 200:  reached
  * |grad f| &lt; 1.0e-8: not reached
Overall: reached
This indicates convergence: No

## Debug
    :Iteration = [(:Iteration, &quot;# %-6d&quot;), (:Cost, &quot;f(x): %f&quot;), (:GradientNorm, &quot;|grad f(p)|:%s&quot;), &quot;\n&quot;, 50]</code></pre><p>From the final cost we can already see that <code>q1</code> is an eigenvector to the smallest eigenvalue we obtaines above.</p><p>And we can compare this to running with the Riemannian gradient, since the <a href="../../objectives/#ManoptExamples.RayleighQuotientGrad!!"><code>RayleighQuotientGrad!!</code></a> returns this one as well, when just called with the sphere as first Argument, we just have to remove the <code>objective_type</code>.</p><pre><code class="language-julia hljs">q2 = gradient_descent(M, f, grad_f, p0;
    debug = [:Iteration, :Cost, :GradientNorm, 50, &quot;\n&quot;],
)
#Test that both are the same
isapprox(M, q1,q2)</code></pre><pre><code class="nohighlight hljs">Initial f(x): -0.000727
# 50    f(x): -0.088242|grad f(p)|:0.0038704743269815734
# 100   f(x): -0.088680|grad f(p)|:0.0034956568288633714
# 150   f(x): -0.089026|grad f(p)|:0.002651478167692353
# 200   f(x): -0.089178|grad f(p)|:0.0015311603359229782

true</code></pre><p>We can also benchmark both</p><pre><code class="language-julia hljs">@benchmark gradient_descent($M, $f, $grad_f, $p0; objective_type=:Euclidean)</code></pre><pre><code class="nohighlight hljs">BenchmarkTools.Trial: 24 samples with 1 evaluation per sample.
 Range (min ‚Ä¶ max):  201.787 ms ‚Ä¶ 260.912 ms  ‚îä GC (min ‚Ä¶ max): 7.25% ‚Ä¶ 0.97%
 Time  (median):     208.678 ms               ‚îä GC (median):    7.35%
 Time  (mean ¬± œÉ):   212.004 ms ¬±  12.605 ms  ‚îä GC (mean ¬± œÉ):  7.55% ¬± 2.09%

  ‚ñà‚ñÉ   ‚ñÉ‚ñÉ‚ñà‚ñÉ                                                      
  ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñá‚ñá‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñá ‚ñÅ
  202 ms           Histogram: frequency by time          261 ms &lt;

 Memory estimate: 771.46 MiB, allocs estimate: 7427.</code></pre><pre><code class="language-julia hljs">@benchmark gradient_descent($M, $f, $grad_f, $p0)</code></pre><pre><code class="nohighlight hljs">BenchmarkTools.Trial: 202 samples with 1 evaluation per sample.
 Range (min ‚Ä¶ max):  23.629 ms ‚Ä¶ 31.627 ms  ‚îä GC (min ‚Ä¶ max): 0.00% ‚Ä¶ 22.42%
 Time  (median):     24.350 ms              ‚îä GC (median):    2.21%
 Time  (mean ¬± œÉ):   24.756 ms ¬±  1.244 ms  ‚îä GC (mean ¬± œÉ):  1.83% ¬±  2.29%

    ‚ñà  ‚ñÇ                                                       
  ‚ñÑ‚ñà‚ñà‚ñá‚ñÖ‚ñà‚ñà‚ñÜ‚ñÑ‚ñá‚ñÑ‚ñÑ‚ñÉ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ ‚ñÉ
  23.6 ms         Histogram: frequency by time        30.3 ms &lt;

 Memory estimate: 8.90 MiB, allocs estimate: 7412.</code></pre><p>From these results we see, that the conversion from the Euclidean to the Riemannian gradient does require a small amount of effort and hence reduces the performance slighly. Still, if the Euclidean Gradient is easier to compute or already available, this is in terms of coding the faster way. Finally this is a tradeoff between derivation and implementation efforts for the Riemannian gradient and a slight performance reduction when using the Euclidean one.</p><h3 id="A-Solver-based-(also)-on-(approximate)-Hessian-information"><a class="docs-heading-anchor" href="#A-Solver-based-(also)-on-(approximate)-Hessian-information">A Solver based (also) on (approximate) Hessian information</a><a id="A-Solver-based-(also)-on-(approximate)-Hessian-information-1"></a><a class="docs-heading-anchor-permalink" href="#A-Solver-based-(also)-on-(approximate)-Hessian-information" title="Permalink"></a></h3><p>To also involve the Hessian, we consider the <a href="https://manoptjl.org/stable/solvers/trust_regions/">trust regions</a> solver with three cases:</p><ol><li>Euclidean, approximating the Hessian</li><li>Euclidean, providing the Hessian</li><li>Riemannian, providing the Hessian but also using in-place evaluations.</li></ol><pre><code class="language-julia hljs">q3 = trust_regions(M, f, grad_f, p0; objective_type=:Euclidean,
    debug = [:Iteration, :Cost, :GradientNorm, 10, &quot;\n&quot;],
);</code></pre><pre><code class="nohighlight hljs">Initial f(x): -0.000727
# 10    f(x): -0.088412|grad f(p)|:0.020989167846023046
# 20    f(x): -0.089079|grad f(p)|:0.007420373217153763
# 30    f(x): -0.089095|grad f(p)|:0.0022962557538450884
# 40    f(x): -0.089095|grad f(p)|:0.0022962557538450884
# 50    f(x): -0.089095|grad f(p)|:0.002296255752372694
# 60    f(x): -0.089095|grad f(p)|:0.002296255750900326
# 70    f(x): -0.089095|grad f(p)|:0.002296255749427973
# 80    f(x): -0.089095|grad f(p)|:0.0022962557479555895
# 90    f(x): -0.089095|grad f(p)|:0.002296255746483256
# 100   f(x): -0.089095|grad f(p)|:0.002296255745010824
# 110   f(x): -0.089095|grad f(p)|:0.0022962557435384336
# 120   f(x): -0.089095|grad f(p)|:0.0022962557420660814
# 130   f(x): -0.089095|grad f(p)|:0.0022962557405937175
# 140   f(x): -0.089095|grad f(p)|:0.0022962557391213406
# 150   f(x): -0.089095|grad f(p)|:0.0022962557376489472
# 160   f(x): -0.089095|grad f(p)|:0.0022962557361765603
# 170   f(x): -0.089095|grad f(p)|:0.0022962557347042086
# 180   f(x): -0.089095|grad f(p)|:0.0022962557332318594
# 190   f(x): -0.089095|grad f(p)|:0.002296255731759444
# 200   f(x): -0.089095|grad f(p)|:0.0022962557302870605
# 210   f(x): -0.089095|grad f(p)|:0.002296255728814736
# 220   f(x): -0.089095|grad f(p)|:0.0022962557273423162
# 230   f(x): -0.089095|grad f(p)|:0.002296255725869944
# 240   f(x): -0.089095|grad f(p)|:0.002296255724397584
# 250   f(x): -0.089095|grad f(p)|:0.0022962557229252085
# 260   f(x): -0.089095|grad f(p)|:0.0022962557214528346
# 270   f(x): -0.089095|grad f(p)|:0.0022962557199804855
# 280   f(x): -0.089095|grad f(p)|:0.0022962557185080726
# 290   f(x): -0.089095|grad f(p)|:0.002296255717035685
# 300   f(x): -0.089095|grad f(p)|:0.0022962557155633144
# 310   f(x): -0.089095|grad f(p)|:0.0022962557140909605
# 320   f(x): -0.089095|grad f(p)|:0.002296255712618571
# 330   f(x): -0.089095|grad f(p)|:0.0022962557111461876
# 340   f(x): -0.089095|grad f(p)|:0.002296255709673808
# 350   f(x): -0.089095|grad f(p)|:0.0022962557082014416
# 360   f(x): -0.089095|grad f(p)|:0.00229625570672907
# 370   f(x): -0.089095|grad f(p)|:0.002296255705256684
# 380   f(x): -0.089095|grad f(p)|:0.0022962557037843165
# 390   f(x): -0.089095|grad f(p)|:0.002296255702311948
# 400   f(x): -0.089095|grad f(p)|:0.0022962557008395722
# 410   f(x): -0.089095|grad f(p)|:0.002296255699367198
# 420   f(x): -0.089095|grad f(p)|:0.0022962556978947854
# 430   f(x): -0.089095|grad f(p)|:0.002296255696422434
# 440   f(x): -0.089095|grad f(p)|:0.0022962556949500715
# 450   f(x): -0.089095|grad f(p)|:0.002296255693477701
# 460   f(x): -0.089095|grad f(p)|:0.0022962556920053264
# 470   f(x): -0.089095|grad f(p)|:0.002296255690532953
# 480   f(x): -0.089095|grad f(p)|:0.0022962556890605674
# 490   f(x): -0.089095|grad f(p)|:0.002296255687588196
# 500   f(x): -0.089095|grad f(p)|:0.002296255686115812
# 510   f(x): -0.089095|grad f(p)|:0.0022962556846434557
# 520   f(x): -0.089095|grad f(p)|:0.00229625568317109
# 530   f(x): -0.089095|grad f(p)|:0.0022962556816987227
# 540   f(x): -0.089095|grad f(p)|:0.002296255680226299
# 550   f(x): -0.089095|grad f(p)|:0.0022962556787539364
# 560   f(x): -0.089095|grad f(p)|:0.0022962556772815833
# 570   f(x): -0.089095|grad f(p)|:0.0022962556758091917
# 580   f(x): -0.089095|grad f(p)|:0.0022962556743368473
# 590   f(x): -0.089095|grad f(p)|:0.0022962556728644322
# 600   f(x): -0.089095|grad f(p)|:0.002296255671392082
# 610   f(x): -0.089095|grad f(p)|:0.0022962556699197066
# 620   f(x): -0.089095|grad f(p)|:0.002296255668447314
# 630   f(x): -0.089095|grad f(p)|:0.002296255666974941
# 640   f(x): -0.089095|grad f(p)|:0.002296255665502539
# 650   f(x): -0.089095|grad f(p)|:0.002296255664030171
# 660   f(x): -0.089095|grad f(p)|:0.002296255662557798
# 670   f(x): -0.089095|grad f(p)|:0.0022962556610854248
# 680   f(x): -0.089095|grad f(p)|:0.002296255659613032
# 690   f(x): -0.089095|grad f(p)|:0.0022962556581407082
# 700   f(x): -0.089095|grad f(p)|:0.002296255656668318
# 710   f(x): -0.089095|grad f(p)|:0.0022962556551958985
# 720   f(x): -0.089095|grad f(p)|:0.002296255653723546
# 730   f(x): -0.089095|grad f(p)|:0.002296255652251183
# 740   f(x): -0.089095|grad f(p)|:0.0022962556507788168
# 750   f(x): -0.089095|grad f(p)|:0.0022962556493064516
# 760   f(x): -0.089095|grad f(p)|:0.002296255647834051
# 770   f(x): -0.089095|grad f(p)|:0.002296255646361663
# 780   f(x): -0.089095|grad f(p)|:0.0022962556448893287
# 790   f(x): -0.089095|grad f(p)|:0.0022962556434169014
# 800   f(x): -0.089095|grad f(p)|:0.0022962556419445497
# 810   f(x): -0.089095|grad f(p)|:0.0022962556404721797
# 820   f(x): -0.089095|grad f(p)|:0.0022962556389998293
# 830   f(x): -0.089095|grad f(p)|:0.002296255637527417
# 840   f(x): -0.089095|grad f(p)|:0.0022962556360550538
# 850   f(x): -0.089095|grad f(p)|:0.00229625563458268
# 860   f(x): -0.089095|grad f(p)|:0.002296255633110347
# 870   f(x): -0.089095|grad f(p)|:0.0022962556316379126
# 880   f(x): -0.089095|grad f(p)|:0.0022962556301655314
# 890   f(x): -0.089095|grad f(p)|:0.0022962556286931957
# 900   f(x): -0.089095|grad f(p)|:0.002296255627220805
# 910   f(x): -0.089095|grad f(p)|:0.0022962556257484328
# 920   f(x): -0.089095|grad f(p)|:0.0022962556242760554
# 930   f(x): -0.089095|grad f(p)|:0.0022962556228036954
# 940   f(x): -0.089095|grad f(p)|:0.002296255621331309
# 950   f(x): -0.089095|grad f(p)|:0.0022962556198589204
# 960   f(x): -0.089095|grad f(p)|:0.0022962556183865473
# 970   f(x): -0.089095|grad f(p)|:0.002296255616914149
# 980   f(x): -0.089095|grad f(p)|:0.0022962556154418005
# 990   f(x): -0.089095|grad f(p)|:0.0022962556139694153
# 1000  f(x): -0.089095|grad f(p)|:0.0022962556124970193</code></pre><p>To provide the Hessian in the high-level interface we need to prodive it as an anonymous function, since any <code>struct</code> is considered to (eventually) be the also optional starting point. For space reasons, let‚Äôs also shorten the debug print to only iterations 7 and 14.</p><pre><code class="language-julia hljs">q4 = trust_regions(M, f, grad_f, (E, p, X) -&gt; Hess_f(E, p, X), p0; objective_type=:Euclidean,
    debug = [:Iteration, :Cost, :GradientNorm, 10, &quot;\n&quot;],
);</code></pre><pre><code class="nohighlight hljs">Initial f(x): -0.000727
# 10    f(x): -0.089234|grad f(p)|:0.0013561755210368023</code></pre><pre><code class="language-julia hljs">q5 = trust_regions(M, f, grad_f, (M, Y, p, X) -&gt; Hess_f(M, Y, p, X), p0;
    evaluation=InplaceEvaluation(),
    debug = [:Iteration, :Cost, :GradientNorm, 10, &quot;\n&quot;],
);</code></pre><pre><code class="nohighlight hljs">Initial f(x): -0.000727
# 10    f(x): -0.089234|grad f(p)|:0.0013561755210368012</code></pre><p>Let‚Äôs also here compare them in benchmarks. Let‚Äôs here compare all variants in their (more performant) in-place versions.</p><pre><code class="language-julia hljs">@benchmark trust_regions($M, $f, $grad_f, $p0;
  objective_type=:Euclidean,
  evaluation=InplaceEvaluation(),
)</code></pre><pre><code class="nohighlight hljs">BenchmarkTools.Trial: 8 samples with 1 evaluation per sample.
 Range (min ‚Ä¶ max):  641.588 ms ‚Ä¶ 683.603 ms  ‚îä GC (min ‚Ä¶ max): 7.17% ‚Ä¶ 4.98%
 Time  (median):     646.807 ms               ‚îä GC (median):    7.35%
 Time  (mean ¬± œÉ):   650.863 ms ¬±  13.648 ms  ‚îä GC (mean ¬± œÉ):  7.14% ¬± 0.93%

  ‚ñà‚ñà  ‚ñà‚ñà   ‚ñà ‚ñà  ‚ñà                                             ‚ñà  
  ‚ñà‚ñà‚ñÅ‚ñÅ‚ñà‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà ‚ñÅ
  642 ms           Histogram: frequency by time          684 ms &lt;

 Memory estimate: 1.96 GiB, allocs estimate: 76973.</code></pre><pre><code class="language-julia hljs">@benchmark trust_regions($M, $f, $grad_f, $((E, Y, p, X) -&gt; Hess_f(E, Y, p, X)), $p0;
  evaluation=InplaceEvaluation(),
  objective_type=:Euclidean
)</code></pre><pre><code class="nohighlight hljs">BenchmarkTools.Trial: 230 samples with 1 evaluation per sample.
 Range (min ‚Ä¶ max):  19.642 ms ‚Ä¶ 39.149 ms  ‚îä GC (min ‚Ä¶ max): 0.00% ‚Ä¶ 0.00%
 Time  (median):     21.517 ms              ‚îä GC (median):    6.14%
 Time  (mean ¬± œÉ):   21.726 ms ¬±  1.736 ms  ‚îä GC (mean ¬± œÉ):  5.95% ¬± 2.33%

             ‚ñÜ‚ñá‚ñÖ‚ñÖ‚ñÅ‚ñà‚ñÜ‚ñÑ‚ñà‚ñÉ ‚ñÜ                                      
  ‚ñÖ‚ñÑ‚ñÅ‚ñÉ‚ñÑ‚ñÉ‚ñÅ‚ñÉ‚ñÉ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñá‚ñá‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ‚ñÖ‚ñÑ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÉ ‚ñÑ
  19.6 ms         Histogram: frequency by time          26 ms &lt;

 Memory estimate: 45.03 MiB, allocs estimate: 14206.</code></pre><pre><code class="language-julia hljs">@benchmark trust_regions($M, $f, $grad_f, $((M, Y, p, X) -&gt; Hess_f(M, Y, p, X)), $p0;
    evaluation=InplaceEvaluation(),
)</code></pre><pre><code class="nohighlight hljs">BenchmarkTools.Trial: 358 samples with 1 evaluation per sample.
 Range (min ‚Ä¶ max):  12.804 ms ‚Ä¶ 22.110 ms  ‚îä GC (min ‚Ä¶ max): 0.00% ‚Ä¶ 12.56%
 Time  (median):     13.816 ms              ‚îä GC (median):    5.56%
 Time  (mean ¬± œÉ):   13.956 ms ¬±  1.191 ms  ‚îä GC (mean ¬± œÉ):  5.32% ¬±  3.18%

   ‚ñÉ‚ñÑ‚ñà ‚ñÅ ‚ñÅ ‚ñÑ‚ñÑ ‚ñÇ ‚ñÅ                                              
  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñÜ‚ñÑ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ ‚ñÉ
  12.8 ms         Histogram: frequency by time          20 ms &lt;

 Memory estimate: 16.46 MiB, allocs estimate: 14182.</code></pre><p>We see that Hessian approximation is quite costly, and Gradient and Hessian conversion somewhat costly; still, they also might serve as a good starting point, before deciding to delve into computing Riemannian gradients and Hessians.</p><p>Of course all 5 runs obtained solutions close by; one might consider the gradient based runs to not have fully converged.</p><pre><code class="language-julia hljs">[distance(M, q1, q) for q ‚àà [q2,q3] ]</code></pre><pre><code class="nohighlight hljs">2-element Vector{Float64}:
 8.835276992173579e-16
 0.8953986994946139</code></pre><pre><code class="language-julia hljs">[distance(M, q3, q) for q ‚àà [q4,q5] ]</code></pre><pre><code class="nohighlight hljs">2-element Vector{Float64}:
 1.1159334410358788
 1.1159334410358788</code></pre><p>Which we can also see in the final cost, comparing it to the Eigenvalue</p><pre><code class="language-julia hljs">[f(M, q) - Œª for q ‚àà [q1, q2, q3, q4, q5] ]</code></pre><pre><code class="nohighlight hljs">5-element Vector{Float64}:
  6.211293387550776e-5
  6.211293387559103e-5
  0.0001451688142172225
 -5.551115123125783e-17
 -5.551115123125783e-17</code></pre><h2 id="Summary"><a class="docs-heading-anchor" href="#Summary">Summary</a><a id="Summary-1"></a><a class="docs-heading-anchor-permalink" href="#Summary" title="Permalink"></a></h2><p>We illustrated several possibilities to call solvers, with both Euclidean gradient and Hessian and Riemannian gradient and Hessian, allocating and in-place function. While the performance is better for the Riemannian case, the Euclidean one is a worthy alternative, when those are easier to compute.</p><h2 id="Literature"><a class="docs-heading-anchor" href="#Literature">Literature</a><a id="Literature-1"></a><a class="docs-heading-anchor-permalink" href="#Literature" title="Permalink"></a></h2><div class="citation noncanonical"><dl><dt>[Bou23]</dt><dd><div>N.¬†Boumal. <a href="https://www.nicolasboumal.net/#book"><em>An Introduction to Optimization on Smooth Manifolds</em></a>. First¬†Edition (<a href="https://doi.org/10.1017/9781009166164">Cambridge University Press, 2023</a>).</div></dd></dl></div></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../HyperparameterOptimization/">¬´ Hyperparameter optimziation</a><a class="docs-footer-nextpage" href="../Riemannian-mean/">Riemannian Mean ¬ª</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.14.1 on <span class="colophon-date" title="Monday 6 October 2025 09:03">Monday 6 October 2025</span>. Using Julia version 1.11.7.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
