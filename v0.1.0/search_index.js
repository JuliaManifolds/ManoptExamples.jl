var documenterSearchIndex = {"docs":
[{"location":"examples/Riemannian-mean/#The-Riemannian-Center-of-Mass-(mean)","page":"Riemannian Mean","title":"The Riemannian Center of Mass (mean)","text":"","category":"section"},{"location":"examples/Riemannian-mean/","page":"Riemannian Mean","title":"Riemannian Mean","text":"Ronny Bergmann 7/2/23","category":"page"},{"location":"examples/Riemannian-mean/#Preliminary-Notes","page":"Riemannian Mean","title":"Preliminary Notes","text":"","category":"section"},{"location":"examples/Riemannian-mean/","page":"Riemannian Mean","title":"Riemannian Mean","text":"Each of the example objectives or problems stated in this package should be accompanied by a Quarto notebook that illustrates their usage, like this one.","category":"page"},{"location":"examples/Riemannian-mean/","page":"Riemannian Mean","title":"Riemannian Mean","text":"For this first example, the objective is a very common one, for example also used in the Get Started: Optimize! tutorial of Manopt.jl.","category":"page"},{"location":"examples/Riemannian-mean/","page":"Riemannian Mean","title":"Riemannian Mean","text":"The second goal of this tutorial is to also illustrate how this package provides these examples, namely in both an easy-to-use and a performant way.","category":"page"},{"location":"examples/Riemannian-mean/","page":"Riemannian Mean","title":"Riemannian Mean","text":"There are two recommended ways to activate a reproducible environment. For most cases the recommended environment is the one in examples/. If you are programming a new, relatively short example, consider using the packages main environment, which is the same as having ManoptExamples.jl in development mode. this requires that your example does not have any (additional) dependencies beyond the ones ManoptExamples.jl has anyways.","category":"page"},{"location":"examples/Riemannian-mean/","page":"Riemannian Mean","title":"Riemannian Mean","text":"For registered versions of ManoptExamples.jl use the environment of examples/ and – under development – add ManoptExamples.jl in development mode from the parent folder. This should be changed after a new example is within a registered version to just use the examples/ environment again.","category":"page"},{"location":"examples/Riemannian-mean/","page":"Riemannian Mean","title":"Riemannian Mean","text":"using Pkg;\nPkg.activate(\".\"); # use the example environment,","category":"page"},{"location":"examples/Riemannian-mean/#Loading-packages-and-defining-data","page":"Riemannian Mean","title":"Loading packages and defining data","text":"","category":"section"},{"location":"examples/Riemannian-mean/","page":"Riemannian Mean","title":"Riemannian Mean","text":"Loading the necessary packages and defining a data set on a manifold","category":"page"},{"location":"examples/Riemannian-mean/","page":"Riemannian Mean","title":"Riemannian Mean","text":"using ManoptExamples, Manopt, Manifolds, ManifoldDiff, Random\nRandom.seed!(42)\nM = Sphere(2)\nn = 100\nσ = π / 8\np = 1 / sqrt(2) * [1.0, 0.0, 1.0]\ndata = [exp(M, p,  σ * rand(M; vector_at=p)) for i in 1:n];","category":"page"},{"location":"examples/Riemannian-mean/#Variant-1:-Using-the-functions","page":"Riemannian Mean","title":"Variant 1: Using the functions","text":"","category":"section"},{"location":"examples/Riemannian-mean/","page":"Riemannian Mean","title":"Riemannian Mean","text":"We can define both the cost and gradient, RiemannianMeanCost and RiemannianMeanGradient!!, respectively. For their mathematical derivation and further explanations, we again refer to Get Started: Optimize!.","category":"page"},{"location":"examples/Riemannian-mean/","page":"Riemannian Mean","title":"Riemannian Mean","text":"f = ManoptExamples.RiemannianMeanCost(data)\ngrad_f = ManoptExamples.RiemannianMeanGradient!!(M, data)","category":"page"},{"location":"examples/Riemannian-mean/","page":"Riemannian Mean","title":"Riemannian Mean","text":"Then we can for example directly call a gradient descent as","category":"page"},{"location":"examples/Riemannian-mean/","page":"Riemannian Mean","title":"Riemannian Mean","text":"x1 = gradient_descent(M, f, grad_f, first(data))","category":"page"},{"location":"examples/Riemannian-mean/","page":"Riemannian Mean","title":"Riemannian Mean","text":"3-element Vector{Float64}:\n 0.6868392794764022\n 0.006531600682543096\n 0.726779982085954","category":"page"},{"location":"examples/Riemannian-mean/#Variant-2:-Using-the-objective","page":"Riemannian Mean","title":"Variant 2: Using the objective","text":"","category":"section"},{"location":"examples/Riemannian-mean/","page":"Riemannian Mean","title":"Riemannian Mean","text":"A shorter way to directly obtain the Manifold objective including these two functions. Here, we want to specify that the objective can do inplace-evaluations using the evaluation=-keyword. The objective can be obtained calling Riemannian_mean_objective as","category":"page"},{"location":"examples/Riemannian-mean/","page":"Riemannian Mean","title":"Riemannian Mean","text":"rmo = ManoptExamples.Riemannian_mean_objective(\n    M, data,\n    evaluation=InplaceEvaluation(),\n)","category":"page"},{"location":"examples/Riemannian-mean/","page":"Riemannian Mean","title":"Riemannian Mean","text":"Together with a manifold, this forms a Manopt Problem, which would usually enable to switch manifolds between solver runs. Here we could for example switch to using Euclidean(3) instead for the same data the objective is build upon.","category":"page"},{"location":"examples/Riemannian-mean/","page":"Riemannian Mean","title":"Riemannian Mean","text":"rmp = DefaultManoptProblem(M, rmo)","category":"page"},{"location":"examples/Riemannian-mean/","page":"Riemannian Mean","title":"Riemannian Mean","text":"This enables us to for example solve the task with different, gradient based, solvers. The first is the same as above, just not using the high-level interface","category":"page"},{"location":"examples/Riemannian-mean/","page":"Riemannian Mean","title":"Riemannian Mean","text":"s1 = GradientDescentState(M, copy(M, first(data)))\nsolve!(rmp, s1)\nx2 = get_solver_result(s1)","category":"page"},{"location":"examples/Riemannian-mean/","page":"Riemannian Mean","title":"Riemannian Mean","text":"3-element Vector{Float64}:\n 0.6868395649618767\n 0.006531393870513675\n 0.7267797141480264","category":"page"},{"location":"examples/Riemannian-mean/","page":"Riemannian Mean","title":"Riemannian Mean","text":"but we can easily use a conjugate gradient instead","category":"page"},{"location":"examples/Riemannian-mean/","page":"Riemannian Mean","title":"Riemannian Mean","text":"s2 = ConjugateGradientDescentState(\n    M,\n    copy(M, first(data)),\n    StopAfterIteration(100),\n    ArmijoLinesearch(M),\n    FletcherReevesCoefficient(),\n)\nsolve!(rmp, s2)\nx3 = get_solver_result(s2)","category":"page"},{"location":"examples/Riemannian-mean/","page":"Riemannian Mean","title":"Riemannian Mean","text":"3-element Vector{Float64}:\n 0.6868393265070905\n 0.006531566700408201\n 0.7267799379452656","category":"page"},{"location":"contributing/","page":"Contributing to ManoptExamples.jl","title":"Contributing to ManoptExamples.jl","text":"EditURL = \"https://github.com/JuliaManifolds/ManoptExamples.jl/blob/master/CONTRIBUTING.md\"","category":"page"},{"location":"contributing/#Contributing-to-Manopt.jl","page":"Contributing to ManoptExamples.jl","title":"Contributing to Manopt.jl","text":"","category":"section"},{"location":"contributing/","page":"Contributing to ManoptExamples.jl","title":"Contributing to ManoptExamples.jl","text":"First, thanks for taking the time to contribute. Any contribution is appreciated and welcome.","category":"page"},{"location":"contributing/","page":"Contributing to ManoptExamples.jl","title":"Contributing to ManoptExamples.jl","text":"The following is a set of guidelines to ManoptExamples.jl.","category":"page"},{"location":"contributing/#Table-of-Contents","page":"Contributing to ManoptExamples.jl","title":"Table of Contents","text":"","category":"section"},{"location":"contributing/","page":"Contributing to ManoptExamples.jl","title":"Contributing to ManoptExamples.jl","text":"Contributing to Manopt.jl\nTable of Contents\nI just have a question\nHow can I file an issue?\nHow can I contribute?\nAdd an objective\nCode style","category":"page"},{"location":"contributing/#I-just-have-a-question","page":"Contributing to ManoptExamples.jl","title":"I just have a question","text":"","category":"section"},{"location":"contributing/","page":"Contributing to ManoptExamples.jl","title":"Contributing to ManoptExamples.jl","text":"The developer can most easily be reached in the Julia Slack channel #manifolds. You can apply for the Julia Slack workspace here if you haven't joined yet. You can also ask your question on our GitHub discussion.","category":"page"},{"location":"contributing/#How-can-I-file-an-issue?","page":"Contributing to ManoptExamples.jl","title":"How can I file an issue?","text":"","category":"section"},{"location":"contributing/","page":"Contributing to ManoptExamples.jl","title":"Contributing to ManoptExamples.jl","text":"If you found a bug or want to propose a feature, we track our issues within the GitHub repository.","category":"page"},{"location":"contributing/#How-can-I-contribute?","page":"Contributing to ManoptExamples.jl","title":"How can I contribute?","text":"","category":"section"},{"location":"contributing/#Add-an-objective","page":"Contributing to ManoptExamples.jl","title":"Add an objective","text":"","category":"section"},{"location":"contributing/","page":"Contributing to ManoptExamples.jl","title":"Contributing to ManoptExamples.jl","text":"The objective in Manopt.jl represents the task to be optimised, usually phrased on an arbitrary manifold. The manifold is later specified when wrapping the objective inside a Problem.","category":"page"},{"location":"contributing/","page":"Contributing to ManoptExamples.jl","title":"Contributing to ManoptExamples.jl","text":"If you have a specific objective you would like to provide here, feel free to start a new file in the src/objectives/ folder in your own fork and propose it later as a Pull Request.","category":"page"},{"location":"contributing/","page":"Contributing to ManoptExamples.jl","title":"Contributing to ManoptExamples.jl","text":"If you objective works without reusing any other objective functions, then they can all just be placed in this one file. If you notice, that you are reusing for example another objectives gradient as part of your objective, please refactor the code, such that the gradient, or other function is in the corresponding file in src/functions/ and follows the naming scheme:","category":"page"},{"location":"contributing/","page":"Contributing to ManoptExamples.jl","title":"Contributing to ManoptExamples.jl","text":"cost functions are always of the form cost_ and a fitting name\ngradient functions are always of the the gradient_ and a fitting name, followed by an !","category":"page"},{"location":"contributing/","page":"Contributing to ManoptExamples.jl","title":"Contributing to ManoptExamples.jl","text":"for in-place gradients and by !! if it is a struct that can provide both.","category":"page"},{"location":"contributing/","page":"Contributing to ManoptExamples.jl","title":"Contributing to ManoptExamples.jl","text":"It would be great if you could also add a small test for the functions and the problem you defined in the test/ section.","category":"page"},{"location":"contributing/#Add-an-example","page":"Contributing to ManoptExamples.jl","title":"Add an example","text":"","category":"section"},{"location":"contributing/","page":"Contributing to ManoptExamples.jl","title":"Contributing to ManoptExamples.jl","text":"If you have used one of the problems from here in an example or you are providing a problem together with an example, please add a corresponding Quarto Markdown file to the examples/ folder. The Markdown file should provide a short introduction to the problem and provide links to further details, maybe a paper or a preprint. Use the bib/literature.yaml file to add references (in CSL_YAML, which can for example be exported e.g. from Zotero).","category":"page"},{"location":"contributing/","page":"Contributing to ManoptExamples.jl","title":"Contributing to ManoptExamples.jl","text":"Add any packages you need to the examples/ environment (see the containting Project.toml). The examples will not be run on CI, but their rendered CommonMark outpout should be included in the list of examples in the documentation of this package.","category":"page"},{"location":"contributing/#Code-style","page":"Contributing to ManoptExamples.jl","title":"Code style","text":"","category":"section"},{"location":"contributing/","page":"Contributing to ManoptExamples.jl","title":"Contributing to ManoptExamples.jl","text":"We try to follow the documentation guidelines from the Julia documentation as well as Blue Style. We run JuliaFormatter.jl on the repo in the way set in the .JuliaFormatter.toml file, which enforces a number of conventions consistent with the Blue Style.","category":"page"},{"location":"contributing/","page":"Contributing to ManoptExamples.jl","title":"Contributing to ManoptExamples.jl","text":"We also follow a few internal conventions:","category":"page"},{"location":"contributing/","page":"Contributing to ManoptExamples.jl","title":"Contributing to ManoptExamples.jl","text":"Any implemented function should be accompanied by its mathematical formulae if a closed form exists.\nwithin a file the structs should come first and functions second. The only exception are constructors for the structs\nwithin both blocks an alphabetical order is preferable.\nThe above implies that the mutating variant of a function follows the non-mutating variant.\nThere should be no dangling = signs.\nAlways add a newline between things of different types (struct/method/const).\nAlways add a newline between methods for different functions (including in-place/non-mutating variants).\nPrefer to have no newline between methods for the same function; when reasonable, merge the docstrings into a generic function signature.\nAll import/using/include should be in the main module file.\nThere should only be a minimum of exports within this file, all problems should usually be later addressed as ManoptExamples.[...]\nthe Quarto Markdown files are excluded from this formatting.","category":"page"},{"location":"objectives/#List-of-Examples","page":"Objectives","title":"List of Examples","text":"","category":"section"},{"location":"objectives/#RiemannianMean","page":"Objectives","title":"Riemannian Mean","text":"","category":"section"},{"location":"objectives/","page":"Objectives","title":"Objectives","text":"See the Riemannian mean example to see these in use.","category":"page"},{"location":"objectives/","page":"Objectives","title":"Objectives","text":"Modules = [ManoptExamples]\nPages = [\"objectives/RiemannianMean.jl\"]\nOrder = [:type, :function]\nPrivate = true","category":"page"},{"location":"objectives/#ManoptExamples.RiemannianMeanCost","page":"Objectives","title":"ManoptExamples.RiemannianMeanCost","text":"RiemannianMeanCost{P}\n\nA functor representing the Riemannian center of mass (or Riemannian mean) cost function.\n\nFor a given set of points d_1ldotsd_N this cost function is defined as\n\nf(p) = sum_j=i^N d_mathcal M^2(d_i p)\n\nwhere d_mathcal M is the distance on a Riemannian manifold.\n\nConstructor\n\nRiemannianMeanCost(M::AbstractManifold, data::AbstractVector{<:P}) where {P}\n\nInitialize the cost function to a data set data of points on a manfiold M, where each point is of type P.\n\nSee also\n\nRiemannianMeanGradient!!, Riemannian_mean_objective\n\n\n\n\n\n","category":"type"},{"location":"objectives/#ManoptExamples.RiemannianMeanGradient!!","page":"Objectives","title":"ManoptExamples.RiemannianMeanGradient!!","text":"RiemannianMeanGradient!!{P} where P\n\nA functor representing the Riemannian center of mass (or Riemannian mean) cost function.\n\nFor a given set of points d_1ldotsd_N this cost function is defined as\n\noperatornamegradf(p) = sum_j=i^N log_p d_i\n\nwhere d_mathcal M is the distance on a Riemannian manifold and we employ grad_distance to compute the single summands.\n\nThis functor provides both the allocating variant grad_f(M,p) as well as the in-place variant grad_f!(M, X, p) which computes the gradient in-place of X.\n\nConstructors\n\nRiemannianMeanGradient!!(data::AbstractVector{P}, initial_vector::T=nothing) where {P,T}\n\nGenerate the Riemannian mean gradient based on some data points data an intial tangent vector initial_vector. If you do not provide an initial tangent vector to allocate the intermediate storage of a tangent vector, you can only use the allocating variant.\n\nRiemannianMeanGradient!!(\n    M::AbstractManifold,\n    data::AbstractVector{P};\n    initial_vector::T=zero_vector(M, first(data)),\n) where {P,T}\n\nInitialize the Riemannian mean gradient, where the internal storage for tangent vectors can be created automatically, since the Riemannian manifold M is provideed.\n\nSee also\n\nRiemannianMeanCost, Riemannian_mean_objective\n\n\n\n\n\n","category":"type"},{"location":"objectives/#ManoptExamples.Riemannian_mean_objective-Tuple{AbstractVector}","page":"Objectives","title":"ManoptExamples.Riemannian_mean_objective","text":"Riemannian_mean_objective(data, initial_vector=nothing, evaluation=AllocatingEvaluation())\nRiemannian_mean_objective(M, data;\ninitial_vector=zero_vector(M, first(data)),\nevaluation=AllocatingEvaluton()\n)\n\nGenerate the objective for the Riemannian mean task for some given vector of data points on the Riemannian manifold M.\n\nSee also\n\nRiemannianMeanCost, RiemannianMeanGradient!!\n\nnote: Note\nThe first constructor should only be used if an additional storage of the vector is not feasible, since initialising the initial_vector to nothing disables the in-place variant. Hence the evaluation is a positional argument, since it only can be changed, if a vector is provided.\n\n\n\n\n\n","category":"method"},{"location":"objectives/#RobustPCA","page":"Objectives","title":"Robust PCA","text":"","category":"section"},{"location":"objectives/","page":"Objectives","title":"Objectives","text":"See the Robust PCA example to see these in use.","category":"page"},{"location":"objectives/","page":"Objectives","title":"Objectives","text":"Modules = [ManoptExamples]\nPages = [\"objectives/RobustPCA.jl\"]\nOrder = [:type, :function]\nPrivate = true","category":"page"},{"location":"objectives/#ManoptExamples.RobustPCACost","page":"Objectives","title":"ManoptExamples.RobustPCACost","text":"RobustPCACost{D,F}\n\nA functor representing the Riemannian robust PCA function on the Grassmann manifold. For some given (column) data Dmathbb R^dtimes n the cost function is defined on some operatornameGr(dm), mn as the sum of the distances of the columns D_i to the subspace spanned by pinoperatornameGr(dm) (represented as a point on the Stiefel manifold). The function reads\n\nf(U) = frac1nsum_i=1^n lVert pp^mathrmTD_i - D_irVert\n\nThis cost additionally provides a Huber regularisation of the cost, that is for some ε0 one use ℓ_ε(x) = sqrtx^2+ε^2 - ε in\n\nf_ε(p) = frac1nsum_i=1^n ℓ_εbigl(lVert pp^mathrmTD_i - D_irVertbigr)\n\nNote that this is a mutable struct so you can adapt the ε later on.\n\nConstructor\n\nRobustPCACost(data::AbstractMatrix, ε=1.0)\nRobustPCACost(M::Grassmann, data::AbstractMatrix, ε=1.0)\n\nInitialize the robust PCA cost to some data D, and some regularization ε. The manifold is optional to comply with all examples, but it is not needed here to construct the cost.\n\n\n\n\n\n","category":"type"},{"location":"objectives/#ManoptExamples.RobustPCAGrad!!","page":"Objectives","title":"ManoptExamples.RobustPCAGrad!!","text":"RobustPCAGrad!!{D,F}\n\nA functor representing the Riemannian robust PCA gradient on the Grassmann manifold. For some given (column) data Xmathbb R^ptimes n the gradient of the RobustPCACost can be computed by projecting the Euclidean gradient onto the corresponding tangent space.\n\nNote that this is a mutable struct so you can adapt the ε later on.\n\nConstructor\n\nRobustPCAGrad!!(data, ε=1.0)\nRobustPCAGrad!!(M::Grassmannian{d,m}, data, ε=1.0; evaluation=AllocatingEvaluation())\n\nInitialize the robust PCA cost to some data D, and some regularization ε. The manifold is optional to comply with all examples, but it is not needed here to construct the cost. Also the evaluation= keyword is present only for unification of the interfaces. Indeed, independent of that keyword the functor always works in both variants.\n\n\n\n\n\n","category":"type"},{"location":"objectives/#ManoptExamples.robust_PCA","page":"Objectives","title":"ManoptExamples.robust_PCA","text":"robust_PCA(data::AbstractMatrix, ε=1.0; evaluation=AllocatingEvaluation())\nrobust_PCA(M, data::AbstractMatrix, ε=1.0; evaluation=AllocatingEvaluton())\n\nGenerate the objective for the robust PCA task for some given data D and Huber regularization parameter ε.\n\nSee also\n\nRobustPCACost, RobustPCAGrad!!\n\nnote: Note\nSince the construction is independent of the manifold, that argument is optional and mainly provided to comply with other objectives. Similarly, independent of the evaluation, indeed the gradient always allows for both the allocating and the inplace variant to be used, though that keyword is used to setup the objective.\n\n\n\n\n\n","category":"function"},{"location":"examples/Robust-PCA/#The-Robust-PCA-computed-on-the-Grassmann-manifold","page":"Robust PCA","title":"The Robust PCA computed on the Grassmann manifold","text":"","category":"section"},{"location":"examples/Robust-PCA/","page":"Robust PCA","title":"Robust PCA","text":"Ronny Bergmann, Laura Weigl 7/2/23","category":"page"},{"location":"examples/Robust-PCA/","page":"Robust PCA","title":"Robust PCA","text":"For this example we first load the necessary packages.","category":"page"},{"location":"examples/Robust-PCA/","page":"Robust PCA","title":"Robust PCA","text":"using Pkg;\nPkg.activate(\".\"); # use the example environment,","category":"page"},{"location":"examples/Robust-PCA/","page":"Robust PCA","title":"Robust PCA","text":"using LinearAlgebra, Random, Statistics\nusing Manifolds, Manopt, ManoptExamples\nusing Plots\nRandom.seed!(42)","category":"page"},{"location":"examples/Robust-PCA/#Computing-a-Robust-PCA","page":"Robust PCA","title":"Computing a Robust PCA","text":"","category":"section"},{"location":"examples/Robust-PCA/","page":"Robust PCA","title":"Robust PCA","text":"For a given matrix D  ℝ^dn whose columns represent points in ℝ^d, a matrix p  ℝ^dm is computed for a given dimension m  n: p represents an ONB of ℝ^dm such that the column space of p approximates the points (columns of D), i.e. the vectors D_i as well as possible.","category":"page"},{"location":"examples/Robust-PCA/","page":"Robust PCA","title":"Robust PCA","text":"We compute p as a minimizer over the Grassmann manifold of the cost function:","category":"page"},{"location":"examples/Robust-PCA/","page":"Robust PCA","title":"Robust PCA","text":"beginsplit\nf(p)\n = frac1nsum_i=1^noperatornamedist(D_i operatornamespan(p))\n\n = frac1n sum_i=1^nlVert pp^TD_i - D_irVert\nendsplit","category":"page"},{"location":"examples/Robust-PCA/","page":"Robust PCA","title":"Robust PCA","text":"The output cost represents the average distance achieved with the returned p, an orthonormal basis (or a point on the Stiefel manifold) representing the subspace (a point on the Grassmann manifold). Notice that norms are not squared, so we have a robust cost function. This means that f is nonsmooth, therefore we regularize with a pseudo-Huber loss function of smoothing parameter ε.","category":"page"},{"location":"examples/Robust-PCA/","page":"Robust PCA","title":"Robust PCA","text":"f_ϵ(p) = frac1n sum_i=1^nℓ_ϵ(lVert pp^mathrmTD_i - D_irVert)","category":"page"},{"location":"examples/Robust-PCA/","page":"Robust PCA","title":"Robust PCA","text":"where ℓ_ϵ(x) = sqrtx^2 + ϵ^2 - ϵ.","category":"page"},{"location":"examples/Robust-PCA/","page":"Robust PCA","title":"Robust PCA","text":"The smoothing parameter is iteratively reduced in the final optimisation runs(with warm starts).","category":"page"},{"location":"examples/Robust-PCA/","page":"Robust PCA","title":"Robust PCA","text":"First, we generate random data. For illustration purposes we take points in mathbb R^2 and m=1, that is we aim to find a robust regression line.","category":"page"},{"location":"examples/Robust-PCA/","page":"Robust PCA","title":"Robust PCA","text":"n = 40\nd = 2\noutliers = 15\ndata = randn(d, 1) * (1:n)' + 0.05 * randn(2, n) .* [1:n 1:n]'\n# Outliers:\npermute = shuffle(1:size(data, 2))'\ndata[:, permute[1:outliers]] = 30 * randn(2, outliers)\n# We are looking for a line here so we set\nm = 1","category":"page"},{"location":"examples/Robust-PCA/","page":"Robust PCA","title":"Robust PCA","text":"We use the Manopt toolbox to optimize the regularized cost function over the Grassmann manifold. To do this, we first need to define the problem structure.","category":"page"},{"location":"examples/Robust-PCA/","page":"Robust PCA","title":"Robust PCA","text":"M = Grassmann(d,m);","category":"page"},{"location":"examples/Robust-PCA/","page":"Robust PCA","title":"Robust PCA","text":"For the initial matrix p_0 we use classical PCA via singular value decomposition. Thus, we use the first d left singular vectors.","category":"page"},{"location":"examples/Robust-PCA/","page":"Robust PCA","title":"Robust PCA","text":"Then, we compute an optimum of the cost function over the Grassmann manifold. We use a trust-region method which is implemented in Manopt.jl.","category":"page"},{"location":"examples/Robust-PCA/","page":"Robust PCA","title":"Robust PCA","text":"Furthermore the cost and gradient are implemented in ManoptExamples.jl. Since these are Huber regularized, both functors have the ϵ as a parameter. To compute the Riemannian gradient we first compute the Euclidian gradient. Afterwards it is projected onto the tangent space by using the orthogonal projection pp^T - I, which converts the Euclidean to the Riemannian gradient.","category":"page"},{"location":"examples/Robust-PCA/","page":"Robust PCA","title":"Robust PCA","text":"The trust-region method also requires the Hessian Matrix. By using ApproxHessianFiniteDifference using a finite difference scheme we get an approximation of the Hessian Matrix.","category":"page"},{"location":"examples/Robust-PCA/","page":"Robust PCA","title":"Robust PCA","text":"We run the procedure several times, where the smoothing parameter ε is reduced iteratively.","category":"page"},{"location":"examples/Robust-PCA/","page":"Robust PCA","title":"Robust PCA","text":"ε = 1.0\niterations = 6\nreduction = 0.5\nU, S, V = svd(data);\np0 = U[:, 1:m]","category":"page"},{"location":"examples/Robust-PCA/","page":"Robust PCA","title":"Robust PCA","text":"2×1 Matrix{Float64}:\n -0.7494248652139394\n  0.6620893983436593","category":"page"},{"location":"examples/Robust-PCA/","page":"Robust PCA","title":"Robust PCA","text":"Let’s generate the cost and gradient we aim to use here","category":"page"},{"location":"examples/Robust-PCA/","page":"Robust PCA","title":"Robust PCA","text":"f = ManoptExamples.RobustPCACost(M, data, ε)\ngrad_f = ManoptExamples.RobustPCAGrad!!(M, data, ε)","category":"page"},{"location":"examples/Robust-PCA/","page":"Robust PCA","title":"Robust PCA","text":"ManoptExamples.RobustPCAGrad!!{Matrix{Float64}, Float64}([9.537606557855465 1.6583418797018163 … 30.833523701909474 30.512999245062304; -45.34339972619071 -1.7120433539256108 … -35.85943792458936 -32.93976007215313], 1.0, [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0])","category":"page"},{"location":"examples/Robust-PCA/","page":"Robust PCA","title":"Robust PCA","text":"and check the initial cost","category":"page"},{"location":"examples/Robust-PCA/","page":"Robust PCA","title":"Robust PCA","text":"f(M, p0)","category":"page"},{"location":"examples/Robust-PCA/","page":"Robust PCA","title":"Robust PCA","text":"9.43069094790552","category":"page"},{"location":"examples/Robust-PCA/","page":"Robust PCA","title":"Robust PCA","text":"Now we iterate the opimization with reducing ε after every iteration, which we update in f and grad_f.","category":"page"},{"location":"examples/Robust-PCA/","page":"Robust PCA","title":"Robust PCA","text":"q = copy(M, p0)\nεi = ε\nfor i in 1:iterations\n    f.ε = εi\n    grad_f.ε = εi\n    global q = trust_regions(\n        M,\n        f,\n        grad_f,\n        ApproxHessianFiniteDifference(\n            M, q, f;\n            vector_transport_method=ProjectionTransport(),\n            retraction_method=PolarRetraction(),\n        ),\n        q;\n        (project!)=project!,\n    )\n    global εi *= reduction\nend","category":"page"},{"location":"examples/Robust-PCA/","page":"Robust PCA","title":"Robust PCA","text":"When finally setting ε we can investigate the final cost","category":"page"},{"location":"examples/Robust-PCA/","page":"Robust PCA","title":"Robust PCA","text":"f.ε = 0.0\nf(M, q)","category":"page"},{"location":"examples/Robust-PCA/","page":"Robust PCA","title":"Robust PCA","text":"9.412965075156471","category":"page"},{"location":"examples/Robust-PCA/","page":"Robust PCA","title":"Robust PCA","text":"Finally, the results are presented visually. The data points are visualized in a scatter plot. The result of the robust PCA and (for comparison) the standard SVD solution are plotted as straight lines.","category":"page"},{"location":"examples/Robust-PCA/","page":"Robust PCA","title":"Robust PCA","text":"fig = plot(data[1, :], data[2, :]; seriestype=:scatter, label=\"Data points\");\nplot!(\n    fig,\n    q[1] * [-1, 1] * 100,\n    q[2] * [-1, 1] * 100;\n    linecolor=:red,\n    linewidth=2,\n    label=\"Robust PCA\",\n);\nplot!(\n    fig,\n    p0[1] * [-1, 1] * 100,\n    p0[2] * [-1, 1] * 100;\n    xlims=1.1 * [minimum(data[1, :]), maximum(data[1, :])],\n    ylims=1.1 * [minimum(data[2, :]), maximum(data[2, :])],\n    linewidth=2,\n    linecolor=:black,\n    label=\"Standard SVD\",\n)","category":"page"},{"location":"examples/Robust-PCA/","page":"Robust PCA","title":"Robust PCA","text":"(Image: Figure 1: The result of the robust PCA vs. SVD)","category":"page"},{"location":"examples/#LIst-of-Examples","page":"Overview","title":"LIst of Examples","text":"","category":"section"},{"location":"examples/","page":"Overview","title":"Overview","text":"Name provides\nRiemannian Mean f, operatornamegradf (A/I), objective 📚\nRobust PCA f, operatornamegradf (A/I), objective 📚","category":"page"},{"location":"examples/","page":"Overview","title":"Overview","text":"Symbols:","category":"page"},{"location":"examples/","page":"Overview","title":"Overview","text":"A Allocating variant\nI In-place variant\n📚 link to documented functions in the documentation","category":"page"},{"location":"#ManoptExample.jl","page":"Home","title":"ManoptExample.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"This package provides a set of example tasks for Manopt.jl based on either generic manifolds from the ManifoldsBase.jl interface or specific manifolds from Manifolds.jl.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Each example usually consists of","category":"page"},{"location":"","page":"Home","title":"Home","text":"a cost function and additional objects, like the gradient or proximal maps, see objectives\nan example explaining how to use these, see examples","category":"page"},{"location":"","page":"Home","title":"Home","text":"Helping functions that are used in one or more examples can be found in the section of functions in the menu.","category":"page"}]
}
