---
title: "Solving Rosenbrock with the Difference of Convex Algorithm"
author: "Ronny Bergmann"
date: 06/06/2023
---

## Introduction

This example illustrates how the [üìñ Rosenbrock](https://en.wikipedia.org/wiki/Rosenbrock_function)
problem can be rephrased as a difference of convex problem and with a new metric on Euclidean space.
This example is the code that produces the results in [@BergmannFerreiraSantosSouza:2023], Section 7.2.

Both the Rosenbrock problem

```math
    \operatorname*{argmin}_{x\in\mathbb R^2} a\bigl( x_1^2-x_2\bigr)^2 + \bigl(x_1-b\bigr)^2,
```
where $a,b>0$ and usually $b=1$ and $a \gg b$,
we know the minimizer $x^* = (b,b^2)^\mathrm{T}$,
and also the (Euclidean) gradient
```math
\nabla f(x) =
  \begin{pmatrix}
  4a(x_1^2-x_2)\\ -2a(x_1^2-x_2)
  \end{pmatrix}
  +
  \begin{pmatrix}
  2(x_1-b)\\ 0
  \end{pmatrix}.
```

They are even available already here in `ManifoldExamples.jl`, see ``[`RosenbrockCost`](@ref ManoptExamples.RosenbrockCost)``{=commonmark} and ``[`RosenbrockGradient!!`](@ref ManoptExamples.RosenbrockGradient!!)``{=commonmark}.

Furthermore, the ``[`RosenbrockMetric`](@ref ManoptExamples.RosenbrockMetric)``{=commonmark} can be used on $\mathbb R^2$, that is

```math
‚ü®X,Y‚ü©_{\mathrm{Rb},p} = X^\mathrm{T}G_pY, \qquad
G_p \coloneqq \begin{pmatrix}
  1+4p_1^2 & -2p_1 \\
  -2p_1 & 1
\end{pmatrix},
```

In this example we want to explore four different approaches to minimizing the Rosenbrock example,
that are all based on first-order methods, i.e. using a gradient but not a Hessian.

1. The Euclidean Gradient
2. The Riemannian gradient descent with respect to the ``[`RosenbrockMetric`](@ref ManoptExamples.RosenbrockMetric)``{=commonmark}
3. The Euclidean Difference of Convex Algorithm
4. The Riemannian Difference of Convex Algorithm respect to the ``[`RosenbrockMetric`](@ref ManoptExamples.RosenbrockMetric)``{=commonmark}

Where we obtain a difference of convex problem by writing

```math
f(x) = a\bigl( x_1^2-x_2\bigr)^2 + \bigl(x_1-b\bigr)^2
 = a\bigl( x_1^2-x_2\bigr)^2 + 2\bigl(x_1-b\bigr)^2 - \bigl(x_1-b\bigr)^2
```
that is
```math
g(x) = a\bigl( x_1^2-x_2\bigr)^2 + 2\bigl(x_1-b\bigr)^2 \quad\text{ and }\quad h(x) = \bigl(x_1-b\bigr)^2
```

```{julia}
#| echo: false
#| code-fold: true
#| output: false
using Pkg;
cd(@__DIR__)
Pkg.activate("."); # for reproducibility use the local tutorial environment.
Pkg.develop(path="../") # a trick to work on the local dev version
ENV["GKSwstype"] = "100"
```

```{julia}
#| output: false
using LinearAlgebra, Random, Statistics
using Manifolds, Manopt, ManoptExamples
using NamedColors, Plots
Random.seed!(42)
```

To emphasize the effect, we choose a quite large value of `a`.

```{julia}
#| output: false
a = 2*10^5
b = 1
```

and use the starting point

```{julia}
p0 = [0.1, 0.2];
```

## The Euclidean Gradient Descent.

For the Euclidean gradient we can just use the same approach as in the [Rosenbrock example](Rosenbrock.md)

```{julia}
M = ‚Ñù^2
f = ManoptExamples.RosenbrockCost(M; a=a, b=b)
‚àáf!! = ManoptExamples.RosenbrockGradient!!(M; a=a, b=b)
```

define a common debug vector

```{julia}
debug_vec = [
        (:Iteration, "# %-8d "),
        (:Cost, "F(x): %1.4e"),
        " ",
        (:Change, "|Œ¥p|: %1.4e | "),
        (:GradientNorm, "|grad f|: %1.6e"),
        :Stop,
        "\n",
    ]
```

and call

```{julia}
pEGD = gradient_descent(M, f, ‚àáf!!, p0;
    evaluation=InplaceEvaluation(),
    debug=[debug_vec...,10^7],
    stopping_criterion=StopAfterIteration(10^8) | StopWhenChangeLess(1e-16),
    record=[:Iteration, :Cost],
    return_state=true,
)
```

## The Riemannian Gradient Descent.

For the Riemannian case, we define

```{julia}
M_rb = MetricManifold(M, ManoptExamples.RosenbrockMetric())
```

and the gradient is now adopted to the new metric

```{julia}
function grad_f!(M, X, p)
    ‚àáf!!(M, X, p)
    riemannian_gradient!(M, X, p, X)
    return X
end
function grad_f(M, p)
    X = zero_vector(M, p)
    return grad_f_rb!(M, X, p)
end
```

and we can first check the gradient again

```{julia}
check_gradient(M_rb, f, grad_f, p0, [0.1, 0.1]; plot=true, io=stdout)
```



```{julia}
pRGD = gradient_descent(M_rb, f, grad_f!, p0;
    evaluation=InplaceEvaluation(),
    debug=[debug_vec...,10^6],
    stopping_criterion=StopAfterIteration(10^8) | StopWhenChangeLess(1e-16),
    record=[:Iteration, :Cost],
    return_state=true,
)
```

## The Euclidean Difference of Convex

For the convex case, we have to first introduce the two parts of the cost.

```{julia}
f1(M, p; a=100, b=1) = a*(p[1]^2 - p[2])^2;
f2(M, p; a=100, b=1) = (p[1] - b[1])^2;
g(M, p; a=100, b=1) = f1(M, p; a=a, b=b) + 2 * f2(M, p; a=a, b=b)
h(M, p; a=100, b=1) = f2(M, p; a=a, b=b)
```

and their (Euclidan) gradients

```{julia}
function ‚àáh!(M, X, p; a=100, b=1)
    X[1] = 2*(p[1]-b)
    X[2] = 0
    return X
end
function ‚àáh(M, p; a=100, b=1)
	X = zero(p)
	‚àáh!(M, X, p; a=a, b=b)
	return X
end
function ‚àág!(M, X, p; a=100, b=1)
    X[1] = 4*a*(p[1]^2-p[2])*p[1] + 2*2*(p[1]-b)
    X[2] = -2*a*(p[1]^2-p[2])
    return X
end
function ‚àág(M, p; a=100, b=1)
	X = zero(p)
	‚àág!(M, X, p; a=a, b=b)
	return X
end
```


```{julia}
check_gradient(M, g, ‚àág, p0, [0.1, 0.1]; plot=true)
```


```{julia}
check_gradient(M, h, ‚àáh, p0, [0.1, 0.1]; plot=true)
```

and we define for convenience

```{julia}
docE_g(M,p) = g(M, p; a=a, b=b)
docE_f(M,p) = docE_g(M,p) - h(M, p; a=a, b=b)
docE_‚àáh!(M, X, p) = ‚àáh!(M, X, p; a=a, b=b)
docE_‚àág!(M, X, p) = ‚àág!(M, X, p; a=a, b=b)
function docE_‚àáf!(M, X, p)
  Y = zero_vector(M, p)
  docE_‚àág!(M, X, p)
  docE_‚àáh!(M, Y, p)
  X .-= Y
  return X
end
```

```{julia}
rec_Edoc = difference_of_convex_algorithm(
	M, docE_f, docE_g, docE_‚àáh!, p0;
    gradient=docE_‚àáf!,
    g=docE_g,
    grad_g = docE_‚àág!,
	evaluation=InplaceEvaluation(),
	debug=[debug_vec..., 5000],
	sub_stopping_criterion=StopAfterIteration(1000) | StopWhenGradientNormLess(1e-16),
	stopping_criterion = StopAfterIteration(10^8) | StopWhenChangeLess(1e-16),
    record = [:Iteration, :Cost],
    return_state=true,
)
```

## Literature

::: {#refs}
:::