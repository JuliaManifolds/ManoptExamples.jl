---
title: "Solving Rosenbrock with the Difference of Convex Algorithm"
author: "Ronny Bergmann"
date: 06/06/2023
---

## Introduction

This example illustrates how the [üìñ Rosenbrock](https://en.wikipedia.org/wiki/Rosenbrock_function)
problem can be rephrased as a difference of convex problem and with a new metric on Euclidean space.
This example is the code that produces the results in [BergmannFerreiraSantosSouza:2023](@cite), Section 7.2.

Both the Rosenbrock problem

```math
    \operatorname*{argmin}_{x\in\mathbb R^2} a\bigl( x_1^2-x_2\bigr)^2 + \bigl(x_1-b\bigr)^2,
```

where $a,b>0$ and usually $b=1$ and $a \gg b$,
we know the minimizer $x^* = (b,b^2)^\mathrm{T}$,
and also the (Euclidean) gradient

```math
\nabla f(x) =
  \begin{pmatrix}
  4a(x_1^2-x_2)\\ -2a(x_1^2-x_2)
  \end{pmatrix}
  +
  \begin{pmatrix}
  2(x_1-b)\\ 0
  \end{pmatrix}.
```

They are even available already here in `ManifoldExamples.jl`, see ``[`RosenbrockCost`](@ref ManoptExamples.RosenbrockCost)``{=commonmark} and ``[`RosenbrockGradient!!`](@ref ManoptExamples.RosenbrockGradient!!)``{=commonmark}.

Furthermore, the ``[`RosenbrockMetric`](@ref ManoptExamples.RosenbrockMetric)``{=commonmark} can be used on $\mathbb R^2$, that is

```math
‚ü®X,Y‚ü©_{\mathrm{Rb},p} = X^\mathrm{T}G_pY, \qquad
G_p = \begin{pmatrix}
  1+4p_1^2 & -2p_1 \\
  -2p_1 & 1
\end{pmatrix},
```

In this example we want to explore four different approaches to minimizing the Rosenbrock example,
that are all based on first-order methods, i.e. using a gradient but not a Hessian.

1. The Euclidean Gradient
2. The Riemannian gradient descent with respect to the ``[`RosenbrockMetric`](@ref ManoptExamples.RosenbrockMetric)``{=commonmark}
3. The Euclidean Difference of Convex Algorithm
4. The Riemannian Difference of Convex Algorithm respect to the ``[`RosenbrockMetric`](@ref ManoptExamples.RosenbrockMetric)``{=commonmark}

Where we obtain a difference of convex problem by writing

```math
f(x) = a\bigl( x_1^2-x_2\bigr)^2 + \bigl(x_1-b\bigr)^2
 = a\bigl( x_1^2-x_2\bigr)^2 + 2\bigl(x_1-b\bigr)^2 - \bigl(x_1-b\bigr)^2
```
that is
```math
g(x) = a\bigl( x_1^2-x_2\bigr)^2 + 2\bigl(x_1-b\bigr)^2 \quad\text{ and }\quad h(x) = \bigl(x_1-b\bigr)^2
```

```{julia}
#| echo: false
#| code-fold: true
#| output: false
using Pkg;
cd(@__DIR__)
Pkg.activate("."); # for reproducibility use the local tutorial environment.
Pkg.develop(path="../") # a trick to work on the local dev version
ENV["GKSwstype"] = "100"
```

```{julia}
#| output: false
using LinearAlgebra, Random, Statistics
using Manifolds, Manopt, ManoptExamples
using NamedColors, Plots
import Manopt: set_manopt_parameter!
Random.seed!(42)
```

```{julia}
#| output: false
paul_tol = load_paul_tol()
indigo = paul_tol["mutedindigo"]
green = paul_tol["mutedgreen"]
sand = paul_tol["mutedsand"]
teal = paul_tol["mutedteal"]
grey = paul_tol["mutedgrey"]
```

To emphasize the effect, we choose a quite large value of `a`.

```{julia}
#| output: false
a = 2*10^5
b = 1
```

and use the starting point and a direction to check gradients

```{julia}
#| output: false
p0 = [0.1, 0.2]
```

## The Euclidean Gradient Descent.

For the Euclidean gradient we can just use the same approach as in the [Rosenbrock example](Rosenbrock.md)

```{julia}
#| output: false
M = ‚Ñù^2
f = ManoptExamples.RosenbrockCost(M; a=a, b=b)
‚àáf!! = ManoptExamples.RosenbrockGradient!!(M; a=a, b=b)
```

define a common debug vector

```{julia}
#| output: false
debug_vec = [
        (:Iteration, "# %-8d "),
        (:Cost, "F(x): %1.4e"),
        " ",
        (:Change, "|Œ¥p|: %1.4e | "),
        (:GradientNorm, "|grad f|: %1.6e"),
        :Stop,
        "\n",
    ]
```

and call the [gradient descent algorithm](https://manoptjl.org/stable/solvers/gradient_descent/#Manopt.gradient_descent)

```{julia}
Eucl_GD_state = gradient_descent(M, f, ‚àáf!!, p0;
    evaluation=InplaceEvaluation(),
    debug=[debug_vec...,10^7],
    stopping_criterion=StopAfterIteration(10^8) | StopWhenChangeLess(1e-16),
    record=[:Iteration, :Cost],
    return_state=true,
)
```

## The Riemannian Gradient Descent.

For the Riemannian case, we define

```{julia}
M_rb = MetricManifold(M, ManoptExamples.RosenbrockMetric())
```

and the gradient is now adopted to the new metric

```{julia}
#| output: false
function grad_f!(M, X, p)
    ‚àáf!!(M, X, p)
    riemannian_gradient!(M, X, p, X)
    return X
end
function grad_f(M, p)
    X = zero_vector(M, p)
    return grad_f!(M, X, p)
end
```

```{julia}
R_GD_state = gradient_descent(M_rb, f, grad_f!, p0;
    evaluation=InplaceEvaluation(),
    debug=[debug_vec...,10^6],
    stopping_criterion=StopAfterIteration(10^8) | StopWhenChangeLess(1e-16),
    record=[:Iteration, :Cost],
    return_state=true,
)
```

## The Euclidean Difference of Convex

For the convex case, we have to first introduce the two parts of the cost.

```{julia}
#| output: false
f1(M, p; a=100, b=1) = a * (p[1]^2 - p[2])^2;
f2(M, p; a=100, b=1) = (p[1] - b[1])^2;
g(M, p; a=100, b=1) = f1(M, p; a=a, b=b) + 2 * f2(M, p; a=a, b=b)
h(M, p; a=100, b=1) = f2(M, p; a=a, b=b)
```

and their (Euclidan) gradients

```{julia}
#| output: false
function ‚àáh!(M, X, p; a=100, b=1)
    X[1] = 2*(p[1]-b)
    X[2] = 0
    return X
end
function ‚àáh(M, p; a=100, b=1)
	X = zero(p)
	‚àáh!(M, X, p; a=a, b=b)
	return X
end
function ‚àág!(M, X, p; a=100, b=1)
    X[1] = 4*a*(p[1]^2-p[2])*p[1] + 2*2*(p[1]-b)
    X[2] = -2*a*(p[1]^2-p[2])
    return X
end
function ‚àág(M, p; a=100, b=1)
	X = zero(p)
	‚àág!(M, X, p; a=a, b=b)
	return X
end
```

and we define for convenience

```{julia}
#| output: false
docE_g(M, p) = g(M, p; a=a, b=b)
docE_f(M,p) = docE_g(M,p) - h(M, p; a=a, b=b)
docE_‚àáh!(M, X, p) = ‚àáh!(M, X, p; a=a, b=b)
docE_‚àág!(M, X, p) = ‚àág!(M, X, p; a=a, b=b)
function docE_‚àáf!(M, X, p)
  Y = zero_vector(M, p)
  docE_‚àág!(M, X, p)
  docE_‚àáh!(M, Y, p)
  X .-= Y
  return X
end
```

Then we call the [difference of convex algorithm](https://manoptjl.org/stable/solvers/difference_of_convex/#Manopt.difference_of_convex_algorithm) on Eucldiean space $\mathbb R^2$.

```{julia}
E_doc_state = difference_of_convex_algorithm(
	M, docE_f, docE_g, docE_‚àáh!, p0;
    gradient=docE_‚àáf!,
    grad_g = docE_‚àág!,
    debug=[debug_vec..., 10^4],
    evaluation=InplaceEvaluation(),
    record=[:Iteration, :Cost],
    stopping_criterion=StopAfterIteration(10^8) | StopWhenChangeLess(1e-16),
    sub_hess=nothing, # Use gradient descent
    sub_stopping_criterion=StopAfterIteration(2000) | StopWhenGradientNormLess(1e-16),
    return_state=true,
)
```

## The Riemannian Difference of Convex

We first have to again defined the gradients with respect to the new metric

```{julia}
#| output: false
function grad_h!(M, X, p; a=100, b=1)
    ‚àáh!(M, X, p; a=a, b=b)
    riemannian_gradient!(M, X, p, X)
    return X
end
function grad_h(M, p; a=100, b=1)
	X = zero(p)
	grad_h!(M, X, p; a=a, b=b)
	return X
end
function grad_g!(M, X, p; a=100, b=1)
    ‚àág!(M, X, p; a=a,b=b)
    riemannian_gradient!(M, X, p, X)
    return X
end
function grad_g(M, p; a=100, b=1)
	X = zero(p)
	grad_g!(M, X, p; a=a, b=b)
	return X
end
```

While the cost of the subgradient can be infered automaticallty, we also have to provide the gradient of the sub problem.
For $X \in \partial h(p^{(k)})$ the sunproblem top determine $p^{(k+1)}$ reads

```math
\operatorname*{argmin}_{p\in\mathcal M} g(p) - \langle X, \log_{p^{(k)}}p\rangle
```

for which usually the cost and gradient functions are computed automatically in the
difference of convex algorithm. However, in our case first the closed form solution for the
adjoint differential of the logaithmic map is complicated to compute and second
the gradint can even be given in a nicer form. We can first simplify in our case
with $X = \operatorname{grad} h(p^{(k)})$ that

```math
\phi(p) = g(p) - \langle X, \log_{p^{(k)}}p\rangle
= a\bigl( p_{1}^2-p_{2}\bigr)^2
        + 2\bigl(p_{1}-b\bigr)^2 - 2(p^{(k)}_1-b)p_1 + 2(p^{(k)}_1-b)p^{(k)}_1,
```

its Euclidean gradient reads

```math
\operatorname{grad}\phi(p) =
    \nabla \varphi(p)
    = \begin{pmatrix}
        4a p_1(p_1^2-p_2) + 4(p_1-b) - 2(p^{(k)}_1-b)\\
        -2a(p_1^2-p_2)
    \end{pmatrix}
```

where we can again employ the gradient conversion from before to obtain the Riemannian gradient.

```{julia}
#| output: false
mutable struct SubGrad{P,T,V}
    pk::P
    Xk::T
    a::V
    b::V
end
function (œï::SubGrad)(M, p)
    X = zero_vector(M, p)
    œï(M, X, p)
    return X
end
function (œï::SubGrad)(M, X, p)
    X .= [
        4 * œï.a * p[1] * (p[1]^2 - p[2]) + 4 * (p[1] - œï.b) - 2 * (œï.pk[1] - œï.b),
        -2 * œï.a * (p[1]^2 - p[2]),
    ]
    riemannian_gradient!(M, X, p, X) # convert
    return X
end
```

And in orer to update the subsolvers gradient correctly, we have to overwrite

```{julia}
#| output: false
set_manopt_parameter!(œï::SubGrad, ::Val{:p}, p) = (œï.pk .= p)
set_manopt_parameter!(œï::SubGrad, ::Val{:X}, X) = (œï.Xk .= X)
```

And we again introduce for ease of use

```{julia}
#| output: false
docR_g(M, p) = g(M, p; a=a, b=b)
docR_f(M, p) = docR_g(M, p) - h(M, p; a=a, b=b)
docR_grad_h!(M, X, p) = grad_h!(M, X, p; a=a, b=b)
docR_grad_g!(M, X, p) = grad_g!(M, X, p; a=a, b=b)
function docR_grad_f!(M, X, p)
    Y = zero_vector(M, p)
    docR_grad_g!(M, X, p)
    docR_grad_h!(M, Y, p)
    X .-= Y
    return X
end
docR_sub_grad = SubGrad(copy(M, p0), zero_vector(M, p0), a, b)
```

Then we can finally call the last of our four algorithms to compare, the
difference of convex algorithm with the Riemannian metric.

```{julia}
R_doc_state = difference_of_convex_algorithm(
    M_rb, docR_f, docR_g, docR_grad_h!, p0;
    gradient=docR_grad_f!,
    grad_g = docR_grad_g!,
    debug=[debug_vec..., 10^6],
    evaluation=InplaceEvaluation(),
    record=[:Iteration, :Cost],
    stopping_criterion=StopAfterIteration(10^8) | StopWhenChangeLess(1e-16),
    sub_grad=docR_sub_grad,
    sub_hess = nothing, # Use gradient descent
    sub_stopping_criterion=StopAfterIteration(2000) | StopWhenGradientNormLess(1e-16),
    return_state=true,
)
```

## Comparison in Iterations

```{julia}
fig = plot(;
    legend=:topright,
    xlabel=raw"Iterations $k$ (log. scale)", ylabel=raw"Cost $f(x)$ (log. scale)",
    yaxis=:log,
    ylims=(1e-16, 5*1e5),
    xaxis=:log,
    xlims=(1,10^8),
)
scatter!(fig, [1,], [f(M,p0),], label=raw"$f(p_0)$", markercolor=grey)
egi = get_record(Eucl_GD_state, :Iteration, :Iteration)[1:10000:end] #5308 entries
egc = get_record(Eucl_GD_state, :Iteration, :Cost)[1:10000:end] #5308 entries
plot!(fig, egi, egc, color=teal, label="Euclidean GD")
#
rgi = get_record(R_GD_state, :Iteration, :Iteration)[1:1000:end] # 2444 entries
rgc = get_record(R_GD_state, :Iteration, :Cost)[1:1000:end] # 2444 entries
plot!(fig, rgi, rgc, color=indigo, label="Riemannian GD")
#
edi = get_record(E_doc_state, :Iteration, :Iteration) #26549 entries
edc = get_record(E_doc_state, :Iteration, :Cost) #26549 entries
plot!(fig, edi, edc, color=sand, label="Euclidean DoC")
#
rdi = get_record(R_doc_state, :Iteration, :Iteration) # 1235 entries
rdc = get_record(R_doc_state, :Iteration, :Cost) # 1235 entries
plot!(fig, rdi, rdc, color=green, label="Riemannian DoC")
```

And we can see that using difference of convex outperforms gradient descent,
and using the Riemannian approach required less iterations than their Euclidean counterparts.

## Literature

````{=commonmark}
```@bibliography
Pages = ["examples/Difference-of-Convex-Rosenbrock.md"]
Canonical=false
```
````